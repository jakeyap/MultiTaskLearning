----- todo -----
modify hierarchical transformer model using huggingface
    check accuracy measurement
    implement model storing on best results
    implement logic to do single task training on either task
    run 1 epoch of full training to time the model
    implement multi gpu
    write readme doc
to get the pkl files up on the remote pc, run the DataProcessor main function.

----- done -----
install tweet tokenizer
try out tweet tokenizer
compare difference to bert tokenizer
merge coarse_discourse dataset with semeval17
tokenize only first 4 posts
stuck at the loss function. debug where it is going wrong
implement test function
implement check 1 test run
implement the length prediction loss
get the modified version to work
set up msi laptop as server at home
check f1 scoring